---
title: "Tidycensus and Reproducible Data in R"
date: "July 23, 2024"
css:
  - |
    .smaller h1 {
      font-size: 0.5em; /* Adjust the font size as needed */
    }
output:
  quarto::quarto_presentation:
    format: revealjs
    theme: 
      logo: images/primary_full-color.png
      theme: theme/slides.scss # Choose a theme for your presentation (e.g., simple, serif, solarized, etc.)
    incremental: true # Whether to display content incrementally (one step at a time)
    self_contained: true # Whether to create a standalone HTML file
    highlight_style: "github" # Syntax highlighting style (e.g., github, monokai, etc.)
    revealjs:
      controls: true # Display navigation controls (e.g., arrows, slide number, etc.)
      progress: true # Display a progress bar
      slideNumber: true # Display slide numbers
      center: true # Center the content on each slide
      chalkboard: true # Enable chalkboard mode for reveal.js
---

```{r}
#| output: false

library(tidyverse)
library(countdown)
library(tigris)
library(sf)
library(scales)
library(edbuildr)
library(viridis)
library(readxl)




bw_primary <- c("#6D1E4A", # 1 plum
                "#007786", # 2 teal
                "#0D525A", # 3 dark green
                "#212B46", # 4 navy
                "#5A6675", # 5 grey
                "#F0DEC1") # 6 cream

bw_secondary <- c("#FFC762", # 1 yellow
                  "#FFB653", # 2 orange
                  "#BEC6CE", # 3 light grey
                  "#2E1A4A", # 4 deep purple
                  "#7EA2D1", # 5 soft blue
                  "#CAD3FB", # 6 lavender
                  "#9CD4EA", # 7 sky
                  "#FFA497") # 8 peach


```

## Agenda

-   Review! 
-   Tidycensus
-   Reproducible data in R

# Review 

## Class #2: The dplyr() package provides many functions to manipulate your data frames' columns and rows {.smaller .scrollable}

The functions you'll most frequently use from the dplyr packages are:

-   `select()`: names columns to keep from a data frame
-   `rename()`: name columns to keep from a data frame
-   `filter()`: remove rows that do not meet the condition in the logical statement from the output
-   `mutate()`: create a new column that will be added to the end of your data frame.



## Class #3: The `ggplot2` package is the most widely-used data visualization approach in the R ecosystem.

-   Plots in `ggplot2` are created by starting with your data, then building up layers
-   Once your specify your data, you can add layers of "geoms" to create your plot

## Class #4: Your data will rarely come in a single table, so you will need to use join functions to merge the data frames {.smaller}

To join two data frames, they need to share a common column with a unique identifier.

State departments of education typically assign a unique ID number to each school district. **Make sure this is available in your data sets.**

Joining data sets on a name (e.g. school or district) can create problems based on:

-   Capitalization (Mcgregor v. McGregor)
-   Abbreviation (St. Paul v. Saint Paul)
-   Mis-spelling (it happens!)

# Tidycensus

## The tidycensus R package is a powerful tool designed to simplify the process of accessing and working with US Census data {.smaller}

::: columns
::: {.column width="60%"}
The Census Bureau collects a lot of information that is reported at the school district level. This includes information on topics that are relevant to school finance, like housing and health. The two main `tidycensus()` functions we will use are:

-   `get_acs()`: Accesses data from 1-year and 5-year American Community Survey samples
-   `get_estimates()`: Interfaces with Population Estimates APIs
:::

::: {.column width="40%" height="45%" fig-align="center"}
![](https://walker-data.com/tidycensus/logo.png){fig-height="50%" fig-align="center"}
:::
:::

## School district geography options in `tidycensus`

In `tidycensus`, you can specify school districts as one of the geography types when pulling data. There are three primary types of school districts to work with:

- **Elementary School Districts**: Represent areas served by elementary schools.
- **Secondary School Districts**: Represent areas served by secondary schools (middle and high schools).
- **Unified School Districts**: Represent areas that serve both elementary and secondary school students.

Most states in the U.S. primarily have unified school districts, which are more common because they serve both elementary and secondary students. However, the exact distribution of school district types varies by by state. Some states may have a mix of elementary, secondary, and unified school districts, while others may predominantly feature one type over the others.

## To get started, you will need to sign up for an API key with the Census Bureau

![](https://michaeldgarber.github.io/teach-r/images/census-api-key-landing.png){fig-align="center"}

[Signup for an API key here!](https://api.census.gov/data/key_signup.html)

# In-class `tidycensus()` exercise

## In the example we will use functions that are part of the `dplyr` package and `ggplot2` packages {.smaller}

-   `anti_join()`: Part of the `dplyr` package and filters observations from one data frame based on non-matches with another data frame.
-   `bind_rows()`: Part of the `dplyr` package and combines multiple data frames or tibbles by stacking them vertically.
-   `facet_wrap()`: Part of the `ggplot2` package and creates multi-panel plots by wrapping a 1D sequence of panels into a 2D layout.

We will also use several functions that we have already learned in the first four classes.


## In-class coding example: clean_and_join.R

```{r}
#| echo: true
#| eval: false

# load -----------

options(scipen = 999)

library(tidyverse)
library(edbuildr)
library(tidycensus)
library(viridis)
library(scales)

# get your own api key from https://api.census.gov/data/key_signup.html
# only run this line of code once after you replace the text below
# with your API key
census_api_key("YOUR API KEY GOES HERE", install = TRUE, overwrite = TRUE)

# get edbuild data
edbuild_fy19 <- masterpull(data_type = "geo")

# load census variables from 2019 acs 5-year estimates
v19 <- load_variables(2019, "acs5", cache = TRUE)

# get mortgage data for unified school districts
mortgage_unified_raw <- get_acs(variables = c("B25101_001", # total households
                                              "B25101_002", # total with a mortgage
                                              "B25101_024"), # total not mortgaged
                        geography = "school district (unified)",
                        state = "MN", 
                        year = 2019)

# get mortgage data for elementary school districts
mortgage_elementary_raw <- get_acs(variables = c("B25101_001", # total households
                                                  "B25101_002", # total with a mortgage
                                                  "B25101_024"), # total not mortgaged
                                    geography = "school district (elementary)",
                                    state = "MN", 
                                    year = 2019)

# get mortgage data for secondary school districts
mortgage_secondary_raw <- get_acs(variables = c("B25101_001", # total households
                                                  "B25101_002", # total with a mortgage
                                                  "B25101_024"), # total not mortgaged
                                    geography = "school district (secondary)",
                                    state = "MN", 
                                    year = 2019)


# clean ------------

# clean mortgage data for unified school districts
mortgage_pct_unified <- mortgage_unified_raw |> 
  # replace vars with more descriptive names
  mutate(variable = str_replace_all(variable, "B25101_001", "households"),
         variable = str_replace_all(variable, "B25101_002", "with_mortgage"),
         variable = str_replace_all(variable, "B25101_024", "no_mortgage")
        ) |>  # close mutate 
  # remove margin of error column
  select(-moe) |> 
  # pivot variable column into distinct columns
  pivot_wider(names_from = variable, values_from = estimate) |> 
  # calculate percent of households within a school district with a mortgage
  mutate(mortgage_pct = with_mortgage / households) 

# clean mortgage data for elementary school districts
mortgage_pct_elementary <- mortgage_elementary_raw |> 
  mutate(variable = str_replace_all(variable, "B25101_001", "households"),
         variable = str_replace_all(variable, "B25101_002", "with_mortgage"),
         variable = str_replace_all(variable, "B25101_024", "no_mortgage")
  ) |>  # close mutate 
  select(-moe) |> 
  pivot_wider(names_from = variable, values_from = estimate) |> 
  mutate(mortgage_pct = with_mortgage / households)

# clean mortgage data for secondary school districts
mortgage_pct_secondary <- mortgage_secondary_raw |> 
  mutate(variable = str_replace_all(variable, "B25101_001", "households"),
         variable = str_replace_all(variable, "B25101_002", "with_mortgage"),
         variable = str_replace_all(variable, "B25101_024", "no_mortgage")
  ) |>  # close mutate 
  select(-moe) |> 
  pivot_wider(names_from = variable, values_from = estimate) |> 
  mutate(mortgage_pct = with_mortgage / households)

# NOTE: this data isn't really that useful for mn!

# join ----------

# join unified and elementary data by binding rows
mortgage_pct_mn <- mortgage_pct_unified |> 
  bind_rows(mortgage_pct_elementary) |> 
  # filter out summary row
  filter(GEOID != "2199999") |> 
  # arrange from largest to smallest district
  arrange(-households)

# join edbuild and census data using left_join
edbuild_mortgage_mn <- edbuild_fy19 |> 
  filter(State == "Minnesota") |> 
  left_join(mortgage_pct_mn, by = c("NCESID" = "GEOID"))

# do the join again, but this time select for the columns we want to keep
# to avoid duplicates like district.x and district.y
edbuild_mortgage_mn <- edbuild_fy19 |> 
  filter(State == "Minnesota") |> 
  left_join(mortgage_pct_mn |> 
              select(GEOID, households, with_mortgage, mortgage_pct),
            by = c("NCESID" = "GEOID"))

# use anti_join() to check for districts with no mortgage data
edbuild_mortgage_mn_no_match <- edbuild_fy19 |> 
  filter(State == "Minnesota") |> 
  anti_join(mortgage_pct_mn |> 
              select(GEOID,households, with_mortgage, mortgage_pct),
            by = c("NCESID" = "GEOID"))

# run the reverse anti_join to see if the census data has 
#  districts not included in the edbuild table
mortgage_edbuild_mn_no_match <- mortgage_pct_mn |> 
  select(GEOID,households, with_mortgage, mortgage_pct) |> 
  anti_join(edbuild_fy19 |> 
              filter(State == "Minnesota") ,
            by = c("GEOID" = "NCESID"))

# plot -----------

# first plot of the joined dataset
ggplot(edbuild_mortgage_mn) +
  geom_point(aes(x = MHI, y = mortgage_pct, 
                 color = StPovRate, size = ENROLL),
             alpha = .7) +
  scale_size_area(max_size = 10, labels = label_comma()) +
  scale_x_continuous(labels = label_dollar()) +
  scale_y_continuous(labels = label_percent()) +
  scale_color_viridis(labels = label_percent()) +
  labs(x = "MHI", y = "Percent of households with a mortgage",
       color = "Poverty rate", size = "Enrollment") +
  theme_bw()

# facet by sdType
ggplot(edbuild_mortgage_mn) +
  geom_point(aes(x = MHI, y = mortgage_pct, 
                 color = StPovRate, size = ENROLL),
             alpha = .7) +
  scale_size_area(max_size = 10, labels = label_comma()) +
  scale_x_continuous(labels = label_dollar()) +
  scale_y_continuous(labels = label_percent()) +
  scale_color_viridis(labels = label_percent()) +
  labs(x = "MHI", y = "Percent of households with a mortgage",
       color = "Poverty rate", size = "Enrollment") +
  facet_wrap(~sdType) +
  theme_bw()

# filter out secondary districts and create better labels for 
# elementary and unified districts
ggplot(edbuild_mortgage_mn |> 
         filter(sdType != "secon") |> 
         mutate(sdType = case_when(sdType == "elem" ~ "Elementary",
                                   sdType == "uni" ~ "Unified"))) +
  geom_point(aes(x = MHI, y = mortgage_pct, 
                 color = StPovRate, size = ENROLL),
             alpha = .7) +
  scale_size_area(max_size = 10, labels = label_comma()) +
  scale_x_continuous(labels = label_dollar()) +
  scale_y_continuous(labels = label_percent()) +
  scale_color_viridis(labels = label_percent()) +
  labs(x = "MHI", y = "Percent of households with a mortgage",
       color = "Poverty rate", size = "Enrollment") +
  facet_wrap(~sdType) +
  theme_bw()

# same chart, but filter  allow for free x+y axis scales
ggplot(edbuild_mortgage_mn |> 
         filter(sdType != "secon") |> 
         mutate(sdType = case_when(sdType == "elem" ~ "Elementary",
                                   sdType == "uni" ~ "Unified"))) +
  geom_point(aes(x = MHI, y = mortgage_pct, 
                 color = StPovRate, size = ENROLL),
             alpha = .7) +
  scale_size_area(max_size = 10, labels = label_comma()) +
  scale_x_continuous(labels = label_dollar()) +
  scale_y_continuous(labels = label_percent()) +
  scale_color_viridis(labels = label_percent()) +
  labs(x = "MHI", y = "Percent of households with a mortgage",
       color = "Poverty rate", size = "Enrollment") +
  facet_wrap(~sdType, scales = "free") +
  theme_bw()



```

# Setting up your data processing project

## You can (and should) start your projects by creating a new repo on your GitHub account

![](week_05/week_5_images/git_new.png){fig-align="center"}

## Before you start coding, set yourself up for a successful, reproducible analysis project

-   Every new data analysis project should live in its own RStudio project
-   Most of your projects should be started on Github, then cloned locally (just like we do with homework)
    -   **Be sure to set your project repos to "Private" before creating them on Github!**
    -   Also, using a `README.md` file can help you stay organized and keep track of data sources and/or outliers.
-   RStudio projects can be also created locally by navigating to `File -> New Project...`, but it's more difficult to connect it to Github if you start that way.

## Remember: After you've created a project, use a consistent folder structure to keep your analysis organized

::: columns
::: {.column width="40%"}
-   Building a consistent file structure in your projects will help you (and others!) easily navigate your code.

-   Minimally, you will want to have a separate folder for:

    -   `data`

    -   `scripts`

    -   `figures`
:::

::: {.column width="60%"}
![](week_05/week_5_images/Screenshot 2024-07-03 at 2.24.37 PM.png){fig-align="center" width="400"}
:::
:::

## Another layer of organization: Separate your raw and processed data!

::: columns
::: {.column width="50%"}
-   Use sub-folders within your `/data` folder to keep your raw data files separated from any processed data files you produce during your analysis.
-   This creates additional procedural barrier to accidentally over-writing your raw data.
-   Use the `/processed` data folder for exporting clean data or results of your analysis, like summary tables.
:::

::: {.column width="50%"}
![](week_05/week_5_images/Screenshot%202023-06-27%20at%204.50.22%20PM.png){fig-align="center" width="475"}
:::
:::

# Homework 

## Homework and Next Steps

- **Our next class is Tuesday, August 13 from 11:00 AM - 12:00 PM CT.** During that class we will go over creating maps and bar charts. 
- There is no homework! 




